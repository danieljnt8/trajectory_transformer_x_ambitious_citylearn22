run_id :
  name : traj_config_v2 ## Difference from v1 is only the quantile strategy 

wandb:
  project: null  # write yours
  name: "city_learn"
  group: "gpt_cache"
  entity: null  # write yours
  mode: "disabled"  # set to online, if needed

dataset:
  env_name: "city_learn"
  seq_len: 10
  cache_path: "data"
  num_bins: ${model.vocab_size}
  discount: 0.99
  strategy: "quantile"
  batch_size: 256

model:
  vocab_size: 100
  transition_dim: 33
  observation_dim: 26
  action_dim: 5
  seq_len: 330 ## transition dim x seq len in dataset
  embedding_dim: 128
  num_layers: 4
  num_heads: 4
  use_sep_heads: true

trainer:
  offline_data_path: "data_interactions/PPO/model_PPO_timesteps_100000_seed_572.pkl"
  num_epochs : 20 
  num_epochs_ref: 50
  action_weight: 5
  value_weight: 1
  reward_weight: 1
  lr: 6e-4
  betas: [0.9, 0.95]
  weight_decay: 0.1
  clip_grad: 1.0
  eval_seed: 42
  eval_every: 10
  eval_episodes: 5
  eval_discount: ${dataset.discount}
  eval_temperature: 1
  eval_plan_every: 1
  eval_beam_width: 32
  eval_beam_steps: 5
  eval_beam_context: 5
  eval_sample_expand: 2
  eval_k_obs: 1
  eval_k_reward: 1
  eval_k_act: null
  checkpoints_path: "checkpoints/${dataset.env_name}/${run_id.name}/${dataset.strategy}/baseline"